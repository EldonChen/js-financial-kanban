# 技术方案设计 - 数据支持模块

> **项目状态**：设计阶段  
> **创建时间**：2025-01-12  
> **文档位置**：docs/  
> **优先级**：P0 - 最高优先级

## 项目概述

数据支持模块是 Phase 3 量化交易算法与回测的基础模块，提供历史K线数据获取与存储、技术指标计算、数据质量保证、数据同步与更新等核心功能。该模块是后续回测引擎和预设算法的基础，必须优先完成。

## 项目技术关键点

### 1. 核心目标

- **历史K线数据管理**：支持多市场、多时间周期的历史K线数据获取、存储、查询
- **技术指标计算**：提供完整的技术指标计算能力，支持基础指标和高级指标
- **数据质量保证**：确保数据的完整性、准确性、一致性
- **数据同步机制**：支持定时任务、增量更新、容错重试
- **高性能查询**：优化数据模型和索引，支持快速查询和批量计算

### 2. 技术栈选型

#### 现有技术栈（保持不变）
- **框架**: FastAPI
- **数据库**: MongoDB
- **数据库驱动**: Motor（异步）
- **数据验证**: Pydantic 2.x
- **包管理**: uv

#### 新增技术栈
- **技术指标计算库**:
  - **TA-Lib**（推荐）：C 库，性能最优，支持 150+ 指标
  - **pandas-ta**（备用）：纯 Python 实现，易于安装，支持 130+ 指标
  - **pandas + numpy**：基础计算库，用于自定义指标
- **数据获取库**:
  - **yfinance**：美股/港股历史K线数据（已使用）
  - **akshare**：A股历史K线数据（已使用）
- **定时任务框架**:
  - **APScheduler**：轻量级，支持异步，易于集成
  - **Celery**（可选）：如果需要分布式任务队列
- **数据缓存**（可选）:
  - **Redis**：缓存热点数据，提升查询性能

## 架构设计决策

### 1. 数据模型设计

#### 1.1 历史K线数据模型（MongoDB TimeSeries Collection）

**集合名称**: `kline_data`

**集合创建**（使用 MongoDB TimeSeries Collection）:
```python
# 创建 TimeSeries Collection
db.create_collection(
    "kline_data",
    timeseries={
        "timeField": "timestamp",      # 时间字段（必填）
        "metaField": "metadata",       # 元数据字段（不经常变化的数据）
        "granularity": "hours"         # 粒度：seconds, minutes, hours
    }
)
```

**文档结构**（使用 metafield 优化存储）:
```python
{
    "_id": ObjectId,
    "timestamp": ISODate("2025-01-12T09:30:00Z"),  # 时间字段（必填，精确到秒）
    "metadata": {                                    # 元数据字段（不经常变化，作为 metafield）
        "ticker": "AAPL",              # 股票代码（必填）
        "market": "NASDAQ",            # 市场（必填）
        "period": "1d"                 # 时间周期（必填）：1m, 5m, 15m, 30m, 60m, 1d, 1w, 1M
    },
    "open": 150.25,                   # 开盘价（必填，测量字段）
    "high": 152.30,                   # 最高价（必填，测量字段）
    "low": 149.80,                    # 最低价（必填，测量字段）
    "close": 151.50,                  # 收盘价（必填，测量字段）
    "volume": 50000000,               # 成交量（必填，测量字段）
    "amount": 7500000000,             # 成交额（可选，A股常用，测量字段）
    "adj_close": 151.50,              # 复权收盘价（可选，用于计算技术指标，测量字段）
    "data_source": "yfinance"         # 数据来源（必填）
}
```

**设计说明**：
- ✅ **使用 metafield**：股票代码、市场、周期等不经常变化的数据存储在 `metadata` 字段中，MongoDB 会自动优化存储
- ✅ **文档引用**：股票详细信息（name, sector, industry 等）存储在独立的 `stocks` 集合中，通过 `metadata.ticker` 引用
- ✅ **存储优化**：metafield 数据只存储一次，多个时间点共享，节省存储空间（通常可节省 50-90%）
- ✅ **查询优化**：MongoDB 可以基于 metafield 进行分区和索引优化，查询性能提升 2-10 倍

**索引设计**（TimeSeries Collection 自动创建，无需手动创建）:
```python
# TimeSeries Collection 会自动创建以下索引：
# 1. 时间字段索引（timestamp）
# 2. metafield 索引（metadata.ticker, metadata.market, metadata.period）
# 3. 复合索引（metadata + timestamp）

# 如果需要额外的查询优化，可以创建以下索引：
# 1. 数据源查询索引（按数据源查询）
db.kline_data.create_index("data_source")
```

**查询示例**:
```python
# 查询特定股票的历史K线数据
db.kline_data.find({
    "metadata.ticker": "AAPL",
    "metadata.period": "1d",
    "timestamp": {
        "$gte": ISODate("2025-01-01"),
        "$lte": ISODate("2025-01-12")
    }
})

# 如果需要股票详细信息，通过 ticker 关联查询
kline_data = db.kline_data.find({"metadata.ticker": "AAPL"})
stock_info = db.stocks.find_one({"ticker": "AAPL"})
```

**冷热数据分离策略**:
- **当前阶段**：使用单一 TimeSeries Collection，依赖 MongoDB 的自动压缩（通常可节省 50-90% 存储空间）
- **数据量 > 1 亿条**：考虑按时间分区（如 `kline_data_recent` 存储最近 1 年数据，`kline_data_archive_2024` 存储历史数据）
- **使用 MongoDB Atlas**：可以使用 Atlas Online Archive，自动归档到 S3，查询透明
- **自动归档**：MongoDB 5.0+ 支持自动归档策略，可以配置数据保留时间

#### 1.2 技术指标数据模型（MongoDB TimeSeries Collection）

**集合名称**: `indicator_data`

**集合创建**（使用 MongoDB TimeSeries Collection）:
```python
# 创建 TimeSeries Collection
db.create_collection(
    "indicator_data",
    timeseries={
        "timeField": "timestamp",      # 时间字段（必填）
        "metaField": "metadata",       # 元数据字段（不经常变化的数据）
        "granularity": "hours"         # 粒度：seconds, minutes, hours
    }
)
```

**文档结构**（使用 metafield 优化存储）:
```python
{
    "_id": ObjectId,
    "timestamp": ISODate("2025-01-12T09:30:00Z"),  # 时间字段（必填，精确到秒）
    "metadata": {                                    # 元数据字段（不经常变化，作为 metafield）
        "ticker": "AAPL",              # 股票代码（必填）
        "period": "1d",                # 时间周期（必填）
        "indicator_type": "MA",        # 指标类型（必填）：MA, EMA, RSI, MACD, BOLL, KDJ, OBV, CCI, ATR, WR
        "indicator_name": "MA20"       # 指标名称（必填）：MA5, MA10, MA20, RSI6, RSI12, MACD_DIF, MACD_DEA, BOLL_UP, BOLL_MID, BOLL_LOW
    },
    "value": 150.25,                  # 指标值（必填，数值类型，测量字段）
    "params": {                        # 指标参数（可选，测量字段）
        "period": 20,                  # 周期参数（如 MA20 的 20）
        "fast": 12,                    # 快速参数（如 MACD 的 12）
        "slow": 26                     # 慢速参数（如 MACD 的 26）
    }
}
```

**设计说明**：
- ✅ **使用 metafield**：股票代码、周期、指标类型、指标名称等不经常变化的数据存储在 `metadata` 字段中
- ✅ **存储优化**：metafield 数据只存储一次，多个时间点共享，节省存储空间
- ✅ **查询优化**：MongoDB 可以基于 metafield 进行分区和索引优化

**索引设计**（TimeSeries Collection 自动创建，无需手动创建）:
```python
# TimeSeries Collection 会自动创建以下索引：
# 1. 时间字段索引（timestamp）
# 2. metafield 索引（metadata.ticker, metadata.period, metadata.indicator_name）
# 3. 复合索引（metadata + timestamp）
```

**查询示例**:
```python
# 查询特定股票的指标数据
db.indicator_data.find({
    "metadata.ticker": "AAPL",
    "metadata.period": "1d",
    "metadata.indicator_name": "MA20",
    "timestamp": {
        "$gte": ISODate("2025-01-01"),
        "$lte": ISODate("2025-01-12")
    }
})
```

#### 1.3 数据质量记录模型

**集合名称**: `data_quality_logs`

**文档结构**:
```python
{
    "_id": ObjectId,
    "ticker": "AAPL",              # 股票代码（必填）
    "period": "1d",                # 时间周期（必填）
    "check_type": "missing_data",   # 检查类型：missing_data, abnormal_value, inconsistent_data, duplicate_data
    "check_date": ISODate("2025-01-12"), # 检查日期
    "status": "fixed",              # 状态：pending, fixed, failed
    "description": "缺失 2025-01-10 的数据", # 问题描述
    "fix_action": "自动补全",        # 修复操作
    "created_at": ISODate,          # 创建时间
    "updated_at": ISODate           # 更新时间
}
```

**索引设计**:
```python
# 1. 查询索引（按股票、周期、检查类型、状态查询）
db.data_quality_logs.create_index([
    ("ticker", 1),
    ("period", 1),
    ("check_type", 1),
    ("status", 1),
    ("check_date", -1)
])
```

### 2. 服务架构设计

> **重要原则**：服务拆分遵循单一职责原则，每个服务类只负责一个功能领域，避免一个文件包含太多职责。

#### 2.1 历史数据服务架构（按功能拆分）

**服务模块位置**: `services/py-stock-info-service/app/services/historical_data/`

**模块结构**:
```
historical_data/
├── __init__.py
├── historical_data_service.py      # 历史数据核心服务（协调各个子服务）
├── historical_data_fetcher.py      # 数据获取服务（从数据源获取K线数据）
├── historical_data_storage.py      # 数据存储服务（保存K线数据到MongoDB）
└── historical_data_query.py        # 数据查询服务（查询K线数据）
```

**核心服务**（`historical_data_service.py`）:

**核心功能**:
- 历史K线数据获取（单只、批量、全量）
- 历史K线数据存储（MongoDB）
- 历史K线数据查询（按股票、时间范围、周期）
- 历史K线数据更新（增量更新、全量更新）
- 历史K线数据删除（清理过期数据）
- 历史K线数据统计（数据覆盖范围、数据量统计）

**核心服务类设计**:
```python
class HistoricalDataService:
    """历史K线数据核心服务（协调各个子服务）."""
    
    def __init__(self, db: Optional[AsyncIOMotorDatabase] = None):
        self.db = db or get_database()
        self.fetcher = HistoricalDataFetcher(db)      # 数据获取服务
        self.storage = HistoricalDataStorage(db)        # 数据存储服务
        self.query = HistoricalDataQuery(db)            # 数据查询服务
    
    async def fetch_kline_data(
        self,
        ticker: str,
        period: str = "1d",
        start_date: Optional[datetime] = None,
        end_date: Optional[datetime] = None,
        data_source: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """获取单只股票的历史K线数据."""
        pass
    
    async def fetch_batch_kline_data(
        self,
        tickers: List[str],
        period: str = "1d",
        start_date: Optional[datetime] = None,
        end_date: Optional[datetime] = None,
        progress_callback: Optional[Callable] = None
    ) -> Dict[str, List[Dict[str, Any]]]:
        """批量获取股票的历史K线数据."""
        pass
    
    async def save_kline_data(
        self,
        ticker: str,
        period: str,
        kline_data: List[Dict[str, Any]],
        data_source: str = "yfinance"
    ) -> int:
        """保存历史K线数据到数据库."""
        pass
    
    async def query_kline_data(
        self,
        ticker: str,
        period: str,
        start_date: Optional[datetime] = None,
        end_date: Optional[datetime] = None,
        limit: Optional[int] = None
    ) -> List[Dict[str, Any]]:
        """查询历史K线数据."""
        pass
    
    async def update_kline_data_incremental(
        self,
        ticker: str,
        period: str = "1d",
        data_source: Optional[str] = None
    ) -> Dict[str, Any]:
        """增量更新历史K线数据（只更新缺失的数据）."""
        pass
    
    async def delete_kline_data(
        self,
        ticker: Optional[str] = None,
        period: Optional[str] = None,
        before_date: Optional[datetime] = None
    ) -> int:
        """删除历史K线数据."""
        pass
    
    async def get_kline_data_statistics(
        self,
        ticker: Optional[str] = None,
        period: Optional[str] = None
    ) -> Dict[str, Any]:
        """获取历史K线数据统计信息."""
        pass
```

**子服务设计**:
```python
class HistoricalDataFetcher:
    """历史K线数据获取服务（从数据源获取数据）."""
    async def fetch_from_yfinance(self, ticker: str, period: str, start_date: datetime, end_date: datetime) -> List[Dict]
    async def fetch_from_akshare(self, ticker: str, period: str, start_date: datetime, end_date: datetime) -> List[Dict]

class HistoricalDataStorage:
    """历史K线数据存储服务（保存数据到MongoDB）."""
    async def save_kline_data(self, ticker: str, period: str, kline_data: List[Dict], data_source: str) -> int
    async def upsert_kline_data(self, ticker: str, period: str, kline_data: List[Dict], data_source: str) -> int

class HistoricalDataQuery:
    """历史K线数据查询服务（查询数据）."""
    async def query_by_ticker(self, ticker: str, period: str, start_date: Optional[datetime], end_date: Optional[datetime]) -> List[Dict]
    async def get_latest_date(self, ticker: str, period: str) -> Optional[datetime]
    async def get_statistics(self, ticker: Optional[str], period: Optional[str]) -> Dict[str, Any]
```

#### 2.2 技术指标服务架构（按功能拆分）

**服务模块位置**: `services/py-stock-info-service/app/services/indicators/`

**模块结构**:
```
indicators/
├── __init__.py
├── indicator_service.py            # 技术指标核心服务（协调各个子服务）
├── indicator_calculator.py         # 指标计算服务（使用 TA-Lib/pandas-ta 计算指标）
├── indicator_storage.py            # 指标存储服务（保存指标数据到MongoDB）
└── indicator_query.py               # 指标查询服务（查询指标数据）
```

**核心功能**:
- 技术指标计算（单指标、批量指标）
- 技术指标数据存储（MongoDB）
- 技术指标数据查询（按股票、指标类型、时间范围）
- 技术指标数据更新（增量更新、全量更新）
- 技术指标计算缓存（提升性能）

**核心服务类设计**:
```python
class IndicatorService:
    """技术指标核心服务（协调各个子服务）."""
    
    def __init__(self, db: Optional[AsyncIOMotorDatabase] = None):
        self.db = db or get_database()
        self.calculator = IndicatorCalculator(db)       # 指标计算服务
        self.storage = IndicatorStorage(db)             # 指标存储服务
        self.query = IndicatorQuery(db)                 # 指标查询服务
        self.historical_data_service = HistoricalDataService(db)
```

**子服务设计**:
```python
class IndicatorCalculator:
    """技术指标计算服务（使用 TA-Lib/pandas-ta 计算指标）."""
    async def calculate_ma(self, ticker: str, period: int, kline_data: List[Dict]) -> List[Dict]
    async def calculate_ema(self, ticker: str, period: int, kline_data: List[Dict]) -> List[Dict]
    async def calculate_rsi(self, ticker: str, period: int, kline_data: List[Dict]) -> List[Dict]
    async def calculate_macd(self, ticker: str, fast: int, slow: int, signal: int, kline_data: List[Dict]) -> List[Dict]
    async def calculate_bollinger_bands(self, ticker: str, period: int, std_dev: float, kline_data: List[Dict]) -> List[Dict]

class IndicatorStorage:
    """技术指标存储服务（保存指标数据到MongoDB）."""
    async def save_indicator_data(self, ticker: str, period: str, indicator_name: str, indicator_data: List[Dict]) -> int
    async def upsert_indicator_data(self, ticker: str, period: str, indicator_name: str, indicator_data: List[Dict]) -> int

class IndicatorQuery:
    """技术指标查询服务（查询指标数据）."""
    async def query_by_indicator(self, ticker: str, indicator_name: str, period: str, start_date: Optional[datetime], end_date: Optional[datetime]) -> List[Dict]
    async def get_supported_indicators(self) -> List[Dict]
```
    
    async def calculate_indicator(
        self,
        ticker: str,
        indicator_type: str,
        indicator_name: str,
        period: str = "1d",
        params: Optional[Dict[str, Any]] = None,
        start_date: Optional[datetime] = None,
        end_date: Optional[datetime] = None,
        use_cache: bool = True
    ) -> List[Dict[str, Any]]:
        """计算单个技术指标."""
        pass
    
    async def calculate_batch_indicators(
        self,
        ticker: str,
        indicator_types: List[str],
        period: str = "1d",
        start_date: Optional[datetime] = None,
        end_date: Optional[datetime] = None,
        progress_callback: Optional[Callable] = None
    ) -> Dict[str, List[Dict[str, Any]]]:
        """批量计算多个技术指标."""
        pass
    
    async def save_indicator_data(
        self,
        ticker: str,
        period: str,
        indicator_name: str,
        indicator_data: List[Dict[str, Any]]
    ) -> int:
        """保存技术指标数据到数据库."""
        pass
    
    async def query_indicator_data(
        self,
        ticker: str,
        indicator_name: str,
        period: str,
        start_date: Optional[datetime] = None,
        end_date: Optional[datetime] = None,
        limit: Optional[int] = None
    ) -> List[Dict[str, Any]]:
        """查询技术指标数据."""
        pass
    
    async def calculate_ma(
        self,
        ticker: str,
        period: int,
        kline_data: Optional[List[Dict[str, Any]]] = None
    ) -> List[Dict[str, Any]]:
        """计算移动平均线（MA）."""
        pass
    
    async def calculate_ema(
        self,
        ticker: str,
        period: int,
        kline_data: Optional[List[Dict[str, Any]]] = None
    ) -> List[Dict[str, Any]]:
        """计算指数移动平均线（EMA）."""
        pass
    
    async def calculate_rsi(
        self,
        ticker: str,
        period: int = 14,
        kline_data: Optional[List[Dict[str, Any]]] = None
    ) -> List[Dict[str, Any]]:
        """计算相对强弱指标（RSI）."""
        pass
    
    async def calculate_macd(
        self,
        ticker: str,
        fast: int = 12,
        slow: int = 26,
        signal: int = 9,
        kline_data: Optional[List[Dict[str, Any]]] = None
    ) -> List[Dict[str, Any]]:
        """计算 MACD 指标."""
        pass
    
    async def calculate_bollinger_bands(
        self,
        ticker: str,
        period: int = 20,
        std_dev: float = 2.0,
        kline_data: Optional[List[Dict[str, Any]]] = None
    ) -> List[Dict[str, Any]]:
        """计算布林带（Bollinger Bands）."""
        pass
```

#### 2.3 数据质量检查服务架构（按功能拆分）

**服务模块位置**: `services/py-stock-info-service/app/services/data_quality/`

**模块结构**:
```
data_quality/
├── __init__.py
├── data_quality_service.py         # 数据质量核心服务（协调各个子服务）
├── completeness_checker.py          # 完整性检查服务
├── accuracy_checker.py              # 准确性检查服务
├── consistency_checker.py           # 一致性检查服务
└── data_fixer.py                    # 数据修复服务
```

**核心功能**:
- 数据完整性检查（缺失数据检测）
- 数据准确性检查（异常值检测、价格合理性检查）
- 数据一致性检查（开盘价、收盘价、最高价、最低价逻辑检查）
- 数据重复检查（去重处理）
- 自动数据修复（缺失数据自动补全）

**核心服务类设计**:
```python
class DataQualityService:
    """数据质量核心服务（协调各个子服务）."""
    
    def __init__(self, db: Optional[AsyncIOMotorDatabase] = None):
        self.db = db or get_database()
        self.completeness_checker = CompletenessChecker(db)    # 完整性检查服务
        self.accuracy_checker = AccuracyChecker(db)            # 准确性检查服务
        self.consistency_checker = ConsistencyChecker(db)      # 一致性检查服务
        self.data_fixer = DataFixer(db)                       # 数据修复服务
        self.historical_data_service = HistoricalDataService(db)
```

**子服务设计**:
```python
class CompletenessChecker:
    """数据完整性检查服务."""
    async def check_missing_data(self, ticker: str, period: str, start_date: datetime, end_date: datetime) -> List[datetime]

class AccuracyChecker:
    """数据准确性检查服务."""
    async def check_abnormal_values(self, ticker: str, period: str, start_date: datetime, end_date: datetime) -> List[Dict]
    async def check_price_reasonableness(self, ticker: str, period: str, start_date: datetime, end_date: datetime) -> List[Dict]

class ConsistencyChecker:
    """数据一致性检查服务."""
    async def check_price_logic(self, ticker: str, period: str, start_date: datetime, end_date: datetime) -> List[Dict]

class DataFixer:
    """数据修复服务."""
    async def fix_missing_data(self, ticker: str, period: str, missing_dates: List[datetime]) -> Dict[str, Any]
    async def fix_duplicate_data(self, ticker: str, period: str) -> Dict[str, Any]
```
    
    async def check_data_completeness(
        self,
        ticker: str,
        period: str = "1d",
        start_date: Optional[datetime] = None,
        end_date: Optional[datetime] = None
    ) -> List[Dict[str, Any]]:
        """检查数据完整性（缺失数据检测）."""
        pass
    
    async def check_data_accuracy(
        self,
        ticker: str,
        period: str = "1d",
        start_date: Optional[datetime] = None,
        end_date: Optional[datetime] = None
    ) -> List[Dict[str, Any]]:
        """检查数据准确性（异常值检测、价格合理性检查）."""
        pass
    
    async def check_data_consistency(
        self,
        ticker: str,
        period: str = "1d",
        start_date: Optional[datetime] = None,
        end_date: Optional[datetime] = None
    ) -> List[Dict[str, Any]]:
        """检查数据一致性（价格逻辑检查）."""
        pass
    
    async def check_duplicate_data(
        self,
        ticker: str,
        period: str = "1d"
    ) -> List[Dict[str, Any]]:
        """检查重复数据."""
        pass
    
    async def fix_missing_data(
        self,
        ticker: str,
        period: str = "1d",
        missing_dates: List[datetime]
    ) -> Dict[str, Any]:
        """自动修复缺失数据."""
        pass
    
    async def run_quality_check(
        self,
        ticker: str,
        period: str = "1d",
        auto_fix: bool = False
    ) -> Dict[str, Any]:
        """运行完整的数据质量检查."""
        pass
```

#### 2.4 数据同步服务架构（按功能拆分）

**服务模块位置**: `services/py-stock-info-service/app/services/data_sync/`

**模块结构**:
```
data_sync/
├── __init__.py
├── data_sync_service.py            # 数据同步核心服务（协调各个子服务）
├── sync_scheduler.py                # 同步调度器（管理定时任务）
└── sync_executor.py                 # 同步执行器（执行同步任务）
```

**核心功能**:
- 定时任务管理（每日数据同步、增量更新）
- 数据同步策略（按市场同步、按优先级同步）
- 同步失败重试（自动重试机制）
- 同步进度追踪（SSE 实时推送）

**核心服务类设计**:
```python
class DataSyncService:
    """数据同步核心服务（协调各个子服务）."""
    
    def __init__(self, db: Optional[AsyncIOMotorDatabase] = None):
        self.db = db or get_database()
        self.scheduler = SyncScheduler(db)                  # 同步调度器
        self.executor = SyncExecutor(db)                   # 同步执行器
        self.historical_data_service = HistoricalDataService(db)
        self.data_quality_service = DataQualityService(db)
```

**子服务设计**:
```python
class SyncScheduler:
    """同步调度器（管理定时任务）."""
    def __init__(self, db: AsyncIOMotorDatabase):
        self.scheduler = AsyncIOScheduler()
    def start(self):  # 启动定时任务
    def add_daily_sync_job(self, market: str, hour: int, minute: int):  # 添加每日同步任务
    def add_quality_check_job(self, day_of_week: str, hour: int, minute: int):  # 添加质量检查任务

class SyncExecutor:
    """同步执行器（执行同步任务）."""
    async def sync_daily_data(self, market: str, period: str, progress_callback: Optional[Callable]) -> Dict[str, Any]
    async def sync_incremental_data(self, ticker: str, period: str, data_source: Optional[str]) -> Dict[str, Any]
    async def sync_market_data(self, market: str, period: str, priority_tickers: Optional[List[str]], progress_callback: Optional[Callable]) -> Dict[str, Any]
```
    
    async def sync_daily_data(
        self,
        market: Optional[str] = None,
        period: str = "1d",
        progress_callback: Optional[Callable] = None
    ) -> Dict[str, Any]:
        """每日数据同步任务."""
        pass
    
    async def sync_incremental_data(
        self,
        ticker: str,
        period: str = "1d",
        data_source: Optional[str] = None
    ) -> Dict[str, Any]:
        """增量数据更新（只更新缺失的数据）."""
        pass
    
    async def sync_market_data(
        self,
        market: str,
        period: str = "1d",
        priority_tickers: Optional[List[str]] = None,
        progress_callback: Optional[Callable] = None
    ) -> Dict[str, Any]:
        """按市场同步数据."""
        pass
    
    def start_scheduler(self):
        """启动定时任务调度器."""
        # 每日 18:00 同步 A股数据
        self.scheduler.add_job(
            self.sync_daily_data,
            trigger="cron",
            hour=18,
            minute=0,
            kwargs={"market": "A股", "period": "1d"}
        )
        
        # 每日 23:00 同步美股数据
        self.scheduler.add_job(
            self.sync_daily_data,
            trigger="cron",
            hour=23,
            minute=0,
            kwargs={"market": "美股", "period": "1d"}
        )
        
        # 每周日 23:00 运行数据质量检查
        self.scheduler.add_job(
            self.data_quality_service.run_quality_check,
            trigger="cron",
            day_of_week="sun",
            hour=23,
            minute=0
        )
        
        self.scheduler.start()
```

### 3. API 接口设计

#### 3.1 历史数据接口

**路由前缀**: `/api/v1/historical-data`

**接口列表**:

1. **获取历史K线数据** - `GET /api/v1/historical-data/{ticker}`
   - **参数**:
     - `ticker` (path): 股票代码
     - `period` (query): 时间周期（1m, 5m, 15m, 30m, 60m, 1d, 1w, 1M），默认 1d
     - `start_date` (query): 开始日期（ISO 8601 格式）
     - `end_date` (query): 结束日期（ISO 8601 格式）
     - `limit` (query): 返回数量限制（默认 1000）
   - **响应**:
     ```json
     {
       "code": 200,
       "message": "success",
       "data": {
         "ticker": "AAPL",
         "period": "1d",
         "count": 100,
         "data": [
           {
             "date": "2025-01-12T00:00:00Z",
             "timestamp": "2025-01-12T00:00:00Z",
             "open": 150.25,
             "high": 152.30,
             "low": 149.80,
             "close": 151.50,
             "volume": 50000000,
             "amount": 7500000000,
             "adj_close": 151.50
           }
         ]
       }
     }
     ```

2. **批量获取历史K线数据** - `POST /api/v1/historical-data/batch`
   - **请求体**:
     ```json
     {
       "tickers": ["AAPL", "MSFT", "GOOGL"],
       "period": "1d",
       "start_date": "2025-01-01T00:00:00Z",
       "end_date": "2025-01-12T00:00:00Z"
     }
     ```
   - **响应**: SSE 流式响应，实时推送进度

3. **更新历史K线数据** - `POST /api/v1/historical-data/{ticker}/update`
   - **参数**:
     - `ticker` (path): 股票代码
     - `period` (query): 时间周期（默认 1d）
     - `incremental` (query): 是否增量更新（默认 true）
     - `data_source` (query): 数据源（可选）
   - **响应**:
     ```json
     {
       "code": 200,
       "message": "更新成功",
       "data": {
         "ticker": "AAPL",
         "period": "1d",
         "updated_count": 10,
         "new_count": 2
       }
     }
     ```

4. **删除历史K线数据** - `DELETE /api/v1/historical-data/{ticker}`
   - **参数**:
     - `ticker` (path): 股票代码（可选，不提供则删除所有）
     - `period` (query): 时间周期（可选）
     - `before_date` (query): 删除指定日期之前的数据（可选）
   - **响应**:
     ```json
     {
       "code": 200,
       "message": "删除成功",
       "data": {
         "deleted_count": 100
       }
     }
     ```

5. **获取历史K线数据统计** - `GET /api/v1/historical-data/{ticker}/statistics`
   - **参数**:
     - `ticker` (path): 股票代码（可选，不提供则返回所有股票的统计）
     - `period` (query): 时间周期（可选）
   - **响应**:
     ```json
     {
       "code": 200,
       "message": "success",
       "data": {
         "ticker": "AAPL",
         "period": "1d",
         "total_count": 1000,
         "start_date": "2020-01-01T00:00:00Z",
         "end_date": "2025-01-12T00:00:00Z",
         "missing_dates": ["2025-01-10", "2025-01-11"]
       }
     }
     ```

#### 3.2 技术指标接口

**路由前缀**: `/api/v1/indicators`

**接口列表**:

1. **计算技术指标** - `POST /api/v1/indicators/calculate`
   - **请求体**:
     ```json
     {
       "ticker": "AAPL",
       "indicator_type": "MA",
       "indicator_name": "MA20",
       "period": "1d",
       "params": {
         "period": 20
       },
       "start_date": "2025-01-01T00:00:00Z",
       "end_date": "2025-01-12T00:00:00Z",
       "use_cache": true
     }
     ```
   - **响应**:
     ```json
     {
       "code": 200,
       "message": "计算成功",
       "data": {
         "ticker": "AAPL",
         "indicator_name": "MA20",
         "period": "1d",
         "count": 100,
         "data": [
           {
             "date": "2025-01-12T00:00:00Z",
             "timestamp": "2025-01-12T00:00:00Z",
             "value": 150.25,
             "params": {
               "period": 20
             }
           }
         ]
       }
     }
     ```

2. **批量计算技术指标** - `POST /api/v1/indicators/batch-calculate`
   - **请求体**:
     ```json
     {
       "ticker": "AAPL",
       "indicator_types": ["MA", "RSI", "MACD"],
       "period": "1d",
       "start_date": "2025-01-01T00:00:00Z",
       "end_date": "2025-01-12T00:00:00Z"
     }
     ```
   - **响应**: SSE 流式响应，实时推送进度

3. **查询技术指标数据** - `GET /api/v1/indicators/{ticker}`
   - **参数**:
     - `ticker` (path): 股票代码
     - `indicator_name` (query): 指标名称（必填）
     - `period` (query): 时间周期（默认 1d）
     - `start_date` (query): 开始日期
     - `end_date` (query): 结束日期
     - `limit` (query): 返回数量限制（默认 1000）
   - **响应**: 与技术指标计算接口相同格式

4. **获取支持的指标列表** - `GET /api/v1/indicators/supported`
   - **响应**:
     ```json
     {
       "code": 200,
       "message": "success",
       "data": {
         "indicators": [
           {
             "type": "MA",
             "name": "MA5",
             "description": "5日移动平均线",
             "params": {
               "period": 5
             }
           },
           {
             "type": "MA",
             "name": "MA10",
             "description": "10日移动平均线",
             "params": {
               "period": 10
             }
           }
         ]
       }
     }
     ```

#### 3.3 数据质量检查接口

**路由前缀**: `/api/v1/data-quality`

**接口列表**:

1. **运行数据质量检查** - `POST /api/v1/data-quality/check`
   - **请求体**:
     ```json
     {
       "ticker": "AAPL",
       "period": "1d",
       "auto_fix": false
     }
     ```
   - **响应**:
     ```json
     {
       "code": 200,
       "message": "检查完成",
       "data": {
         "ticker": "AAPL",
         "period": "1d",
         "completeness": {
           "status": "passed",
           "missing_count": 0
         },
         "accuracy": {
           "status": "passed",
           "abnormal_count": 0
         },
         "consistency": {
           "status": "passed",
           "inconsistent_count": 0
         },
         "duplicate": {
           "status": "passed",
           "duplicate_count": 0
         }
       }
     }
     ```

2. **修复数据问题** - `POST /api/v1/data-quality/fix`
   - **请求体**:
     ```json
     {
       "ticker": "AAPL",
       "period": "1d",
       "fix_type": "missing_data"
     }
     ```
   - **响应**: 修复结果

3. **获取数据质量报告** - `GET /api/v1/data-quality/report`
   - **参数**:
     - `ticker` (query): 股票代码（可选）
     - `period` (query): 时间周期（可选）
     - `start_date` (query): 开始日期（可选）
     - `end_date` (query): 结束日期（可选）
   - **响应**: 数据质量报告

#### 3.4 数据同步接口

**路由前缀**: `/api/v1/data-sync`

**接口列表**:

1. **触发数据同步** - `POST /api/v1/data-sync/sync`
   - **请求体**:
     ```json
     {
       "market": "A股",
       "period": "1d",
       "incremental": true
     }
     ```
   - **响应**: SSE 流式响应，实时推送同步进度

2. **获取同步状态** - `GET /api/v1/data-sync/status`
   - **响应**:
     ```json
     {
       "code": 200,
       "message": "success",
       "data": {
         "last_sync_time": "2025-01-12T18:00:00Z",
         "next_sync_time": "2025-01-13T18:00:00Z",
         "sync_jobs": [
           {
             "market": "A股",
             "period": "1d",
             "status": "completed",
             "last_run": "2025-01-12T18:00:00Z"
           }
         ]
       }
     }
     ```

### 4. 数据流程设计

#### 4.1 历史数据获取流程

**单只股票数据获取流程**:
```
1. 接收请求（ticker, period, start_date, end_date）
2. 检查缓存（可选，Redis）
3. 查询数据库（检查已有数据）
4. 计算缺失数据的时间范围
5. 如果缺失数据：
   a. 选择数据源（yfinance/akshare）
   b. 调用数据源 API 获取数据
   c. 数据验证和清洗
   d. 保存到数据库
6. 返回查询结果（合并已有数据和新增数据）
```

**批量股票数据获取流程**:
```
1. 接收请求（tickers[], period, start_date, end_date）
2. 初始化进度追踪（SSE）
3. 遍历股票列表：
   a. 发送进度更新（当前股票、进度百分比）
   b. 执行单只股票数据获取流程
   c. 记录成功/失败统计
4. 发送完成通知（包含统计信息）
```

**全量股票数据获取流程**:
```
1. 接收请求（market, period）
2. 获取股票列表（从 stocks 集合）
3. 执行批量股票数据获取流程
4. 返回统计结果
```

#### 4.2 技术指标计算流程

**单指标计算流程**:
```
1. 接收请求（ticker, indicator_type, indicator_name, params）
2. 检查缓存（可选，Redis）
3. 如果缓存未命中：
   a. 查询历史K线数据（从 kline_data 集合）
   b. 如果K线数据不足，先获取K线数据
   c. 调用技术指标计算函数（TA-Lib/pandas-ta）
   d. 计算结果验证
   e. 保存到数据库（indicator_data 集合）
   f. 更新缓存
4. 返回计算结果
```

**批量指标计算流程**:
```
1. 接收请求（ticker, indicator_types[], period）
2. 初始化进度追踪（SSE）
3. 遍历指标类型：
   a. 发送进度更新
   b. 执行单指标计算流程
   c. 记录成功/失败统计
4. 发送完成通知
```

#### 4.3 数据质量检查流程

**完整质量检查流程**:
```
1. 接收请求（ticker, period, auto_fix）
2. 执行完整性检查：
   a. 查询数据库，获取已有数据的时间范围
   b. 计算预期的时间范围（交易日）
   c. 找出缺失的日期
   d. 记录到 data_quality_logs
3. 执行准确性检查：
   a. 检查异常值（价格突变、成交量异常）
   b. 检查价格合理性（价格范围、涨跌幅限制）
   c. 记录异常数据
4. 执行一致性检查：
   a. 检查价格逻辑（high >= low, high >= open, high >= close, low <= open, low <= close）
   b. 检查成交量合理性（volume >= 0）
   c. 记录不一致数据
5. 执行重复检查：
   a. 查询重复数据（相同 ticker, period, timestamp）
   b. 记录重复数据
6. 如果 auto_fix = true：
   a. 自动修复缺失数据
   b. 自动修复重复数据
7. 返回检查结果
```

#### 4.4 数据同步流程

**定时任务同步流程**:
```
1. 定时任务触发（每日 18:00 A股，23:00 美股）
2. 获取需要同步的股票列表（从 stocks 集合）
3. 按市场分组
4. 遍历每个市场：
   a. 执行批量股票数据获取流程
   b. 记录同步结果
   c. 如果失败，记录错误日志
5. 发送同步完成通知（可选，邮件/WebSocket）
```

**增量更新流程**:
```
1. 接收请求（ticker, period）
2. 查询数据库，获取最新数据的日期
3. 计算需要更新的时间范围（从最新日期到当前日期）
4. 如果时间范围不为空：
   a. 调用数据源 API 获取新数据
   b. 数据验证和清洗
   c. 保存到数据库（使用 upsert，避免重复）
5. 返回更新结果
```

## 技术难点与解决方案

### 1. 数据量巨大，查询性能优化

**问题**：
- 历史K线数据量巨大（单只股票日线数据 10 年 = 2500 条，1000 只股票 = 250 万条）
- 技术指标数据量也很大（每个指标都需要存储）
- 查询性能可能成为瓶颈

**解决方案**：
- **索引优化**：合理设计复合索引，支持常用查询模式
- **数据分区**：如果数据量超过 1000 万条，考虑按市场或时间分区
- **缓存策略**：使用 Redis 缓存热点数据（最近 1 年的数据、常用指标）
- **查询优化**：限制查询时间范围，使用分页，避免全表扫描
- **数据压缩**：对于历史数据（超过 1 年），可以考虑压缩存储

### 2. 技术指标计算性能

**问题**：
- 技术指标计算可能很耗时（特别是批量计算）
- 需要重复计算相同的数据
- 大规模计算（1000+ 只股票）可能成为性能瓶颈

**解决方案**：
- **当前阶段**（数据规模 < 1 亿条）：
  - **使用 TA-Lib**：C 库，性能最优，单机计算已经足够快
  - **计算结果缓存**：将计算结果存储到数据库，避免重复计算
  - **增量计算**：只计算新增数据对应的指标值
  - **批量计算优化**：使用 pandas 向量化计算，避免循环
  - **异步计算**：对于批量计算，使用异步任务，通过 SSE 推送进度

- **未来阶段**（数据规模 > 1 亿条或需要实时计算）：
  - **考虑引入 Apache Flink**：分布式流处理和批处理框架，支持大规模并行计算
  - **混合方案**：小规模计算用 TA-Lib（单只股票、少量指标），大规模计算用 Flink（批量股票、大量指标）
  - **Flink 实施**：
    - 部署 Flink 集群（3-5 个节点）
    - 开发 Flink Job，实现技术指标计算逻辑
    - 在 FastAPI 服务中集成 Flink API，支持异步提交计算任务
    - 实现混合方案：根据数据规模自动选择计算方式

**Flink 适用场景**：
- ✅ **实时技术指标计算**：实时计算 MA、RSI、MACD 等指标，延迟 < 1 秒
- ✅ **批量技术指标计算**：批量计算 1000+ 只股票的指标，性能提升 10-100 倍
- ✅ **复杂指标计算**：支持窗口函数、状态管理、自定义函数

**Flink 不适用场景**：
- ❌ **小规模数据**：数据量 < 100 万条，Flink 的启动开销可能大于计算收益
- ❌ **简单指标计算**：简单的移动平均线计算，使用 pandas 已经足够
- ❌ **实时性要求不高**：如果只需要每日计算一次，使用定时任务 + pandas 更简单

**当前阶段建议**：**不引入 Flink**，使用 TA-Lib/pandas 进行技术指标计算，如果后续数据规模扩大或需要实时计算，再考虑引入 Flink。

### 3. 数据源不稳定

**问题**：
- yfinance、akshare 等数据源可能不稳定
- 网络请求可能失败
- 数据源 API 可能变更

**解决方案**：
- **多数据源容错**：实现数据源路由器，自动切换备用数据源
- **重试机制**：实现指数退避重试策略
- **数据验证**：对获取的数据进行验证，确保数据质量
- **错误处理**：记录详细的错误日志，便于排查问题
- **降级策略**：如果所有数据源都失败，返回已有数据或错误提示

### 4. 数据质量保证

**问题**：
- 数据源可能返回不完整的数据
- 数据可能存在异常值
- 数据可能存在逻辑错误

**解决方案**：
- **数据验证**：在保存前验证数据格式和范围
- **数据质量检查**：定期运行数据质量检查，发现问题
- **自动修复**：对于缺失数据，自动从数据源补全
- **数据修复记录**：记录所有数据修复操作，便于追溯
- **人工审核**：对于严重的数据问题，需要人工审核

### 5. 定时任务管理

**问题**：
- 需要管理多个定时任务（每日同步、每周质量检查）
- 任务可能失败，需要重试
- 需要追踪任务执行状态

**解决方案**：
- **使用 APScheduler**：轻量级定时任务框架，支持异步
- **任务状态追踪**：记录任务执行状态（pending, running, completed, failed）
- **失败重试**：任务失败后自动重试（最多 3 次）
- **任务日志**：记录详细的任务执行日志
- **任务监控**：提供任务状态查询接口

## 技术选型依据

### 1. 技术指标计算库选型

#### TA-Lib（推荐）

**优势**：
- ✅ **性能最优**：C 库，计算速度快
- ✅ **指标丰富**：支持 150+ 技术指标
- ✅ **准确性高**：经过市场验证，计算准确
- ✅ **社区活跃**：广泛使用，文档完善

**劣势**：
- ⚠️ **安装复杂**：需要编译 C 库，Windows 环境可能有问题
- ⚠️ **依赖系统库**：需要系统安装相关依赖

**选型理由**：
- 性能要求高，需要快速计算大量指标
- 指标准确性要求高，TA-Lib 经过市场验证
- 如果安装有问题，可以使用 pandas-ta 作为备用

#### pandas-ta（备用）

**优势**：
- ✅ **纯 Python 实现**：易于安装，跨平台
- ✅ **指标丰富**：支持 130+ 技术指标
- ✅ **易于扩展**：可以轻松添加自定义指标

**劣势**：
- ⚠️ **性能较低**：纯 Python 实现，计算速度较慢
- ⚠️ **社区较小**：使用人数较少，可能有问题

**选型理由**：
- 作为 TA-Lib 的备用方案
- 如果 TA-Lib 安装失败，可以使用 pandas-ta
- 对于自定义指标，可以使用 pandas-ta 或 pandas + numpy

### 2. 数据存储方案

#### MongoDB TimeSeries Collection（推荐）

**优势**：
- ✅ **时间序列优化**：MongoDB 5.0+ 支持 TimeSeries Collection，针对时间序列数据优化
- ✅ **查询性能**：支持高效的时间范围查询
- ✅ **数据压缩**：自动压缩，节省存储空间
- ✅ **与现有系统一致**：项目已使用 MongoDB

**劣势**：
- ⚠️ **版本要求**：需要 MongoDB 5.0+
- ⚠️ **功能限制**：TimeSeries Collection 不支持某些 MongoDB 功能

**选型理由**：
- 项目已使用 MongoDB，保持一致
- 时间序列数据适合使用 TimeSeries Collection
- 如果 MongoDB 版本 < 5.0，可以使用普通 Collection + 索引优化

### 3. 数据缓存方案

#### Redis（可选）

**优势**：
- ✅ **性能高**：内存存储，查询速度快
- ✅ **支持过期**：可以设置数据过期时间
- ✅ **支持数据结构**：支持字符串、列表、哈希等数据结构

**劣势**：
- ⚠️ **额外依赖**：需要部署 Redis 服务
- ⚠️ **内存限制**：数据量大时可能占用大量内存

**选型理由**：
- 可选方案，如果性能要求不高，可以不使用
- 主要用于缓存热点数据（最近 1 年的数据、常用指标）
- 如果项目规模较小，可以不使用 Redis，直接查询数据库

### 4. 定时任务框架选型

#### APScheduler（推荐）

**优势**：
- ✅ **轻量级**：不需要额外的消息队列
- ✅ **支持异步**：支持 asyncio，与 FastAPI 集成方便
- ✅ **功能完整**：支持 cron、interval、date 等触发器
- ✅ **易于使用**：API 简单，易于集成

**劣势**：
- ⚠️ **单机限制**：不支持分布式任务调度
- ⚠️ **持久化限制**：任务状态存储在内存中，服务重启会丢失

**选型理由**：
- 项目规模较小，不需要分布式任务调度
- 与 FastAPI 集成方便，支持异步
- 如果后续需要分布式，可以迁移到 Celery

#### Celery（可选）

**优势**：
- ✅ **分布式支持**：支持分布式任务调度
- ✅ **持久化**：任务状态可以持久化到数据库
- ✅ **功能强大**：支持任务重试、任务优先级等高级功能

**劣势**：
- ⚠️ **复杂度高**：需要配置消息队列（Redis/RabbitMQ）
- ⚠️ **资源消耗**：需要额外的消息队列服务

**选型理由**：
- 当前阶段不需要，如果后续需要分布式任务调度，可以考虑
- 如果项目规模扩大，需要多实例部署，可以考虑迁移到 Celery

## 参考资料来源

### 技术指标计算

- [TA-Lib 官方文档](https://ta-lib.org/)
- [pandas-ta 文档](https://github.com/twopirllc/pandas-ta)
- [技术指标计算公式](https://www.investopedia.com/terms/t/technicalindicator.asp)

### 数据源文档

- [yfinance 文档](https://github.com/ranaroussi/yfinance)
- [akshare 文档](https://akshare.akfamily.xyz/)

### MongoDB TimeSeries

- [MongoDB TimeSeries Collection 文档](https://www.mongodb.com/docs/manual/core/timeseries-collections/)
- [MongoDB 时间序列数据最佳实践](https://www.mongodb.com/docs/manual/core/timeseries-collections/timeseries-best-practices/)

### 定时任务框架

- [APScheduler 文档](https://apscheduler.readthedocs.io/)
- [Celery 文档](https://docs.celeryproject.org/)

## 向后兼容性保证

### 1. 现有服务不受影响

**设计原则**：
- ✅ **独立集合**：历史K线数据使用新集合 `kline_data`，技术指标数据使用新集合 `indicator_data`，不影响现有 `stocks` 集合
- ✅ **独立路由**：历史数据路由 `/api/v1/historical-data/*`，技术指标路由 `/api/v1/indicators/*`，不影响现有股票路由 `/api/v1/stocks/*`
- ✅ **独立服务**：新增服务类不影响现有 `StockService`，可以独立部署和测试
- ✅ **渐进式迁移**：可以先实现新功能，不影响现有功能，后续可以逐步迁移现有功能到新架构

### 2. 数据模型兼容性

**股票信息存储策略**：
- ✅ **文档引用**：股票详细信息（name, sector, industry 等）存储在独立的 `stocks` 集合中，时间序列数据只存储 ticker 引用
- ✅ **数据一致性**：股票信息更新时，只需要更新 `stocks` 集合，不影响时间序列数据
- ✅ **扩展性**：股票信息可以随时添加新字段，不影响时间序列数据

### 3. 服务拆分兼容性

**服务拆分策略**：
- ✅ **按功能领域拆分**：将服务按功能领域拆分为独立模块（historical_data, indicators, data_quality, data_sync）
- ✅ **保持接口一致**：核心服务接口保持不变，内部实现按功能拆分
- ✅ **向后兼容**：现有代码可以继续使用核心服务接口，无需修改

## 待确认事项

### ⚠️ 需要用户确认的关键点

1. **技术指标计算库选择**：
   - 优先使用 TA-Lib（性能最优）
   - 如果 TA-Lib 安装失败，使用 pandas-ta（备用）
   - 是否需要支持自定义指标计算？
   - **Flink 考虑**：当前阶段不引入 Flink，如果后续数据规模 > 1 亿条或需要实时计算，再考虑引入

2. **数据缓存策略**：
   - 是否需要使用 Redis 缓存？
   - 如果使用，缓存哪些数据？（最近 1 年的K线数据、常用指标）

3. **冷热数据分离策略**：
   - 当前阶段：使用单一 TimeSeries Collection，依赖 MongoDB 自动压缩
   - 数据量 > 1 亿条：考虑按时间分区或使用 Atlas Online Archive
   - 是否需要配置自动归档策略？

4. **定时任务配置**：
   - 每日同步时间（A股 18:00，美股 23:00）是否合适？
   - 是否需要支持自定义定时任务配置？

5. **数据保留策略**：
   - 历史数据保留多长时间？（建议：K线数据保留 10 年，技术指标数据保留 5 年）
   - 是否需要自动清理过期数据？

6. **服务拆分确认**：
   - 服务拆分方案（按功能领域拆分）是否合适？
   - 是否需要进一步细化拆分？

---

**技术架构设计已完成，已根据技术调研结果完善**

**参考文档**：`docs/技术调研-数据支持模块.md`（包含详细的技术调研结果）

**下一步**：等待用户确认后，开始实现基本服务层（历史数据服务、技术指标服务）
