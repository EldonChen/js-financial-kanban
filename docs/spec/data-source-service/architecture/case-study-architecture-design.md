# Case Study：数据源服务技术架构设计思路

本文通过**数据源服务（Data Source Service）**这一具体案例，说明技术架构的设计思路：如何从问题出发做职责划分、如何用抽象与模式支撑动态扩展、以及如何在 SPEC 中固化这些决策。

---

## 一、案例背景：要解决什么问题？

### 1.1 现状痛点

- **多数据源分散**：股票元信息、历史 K 线、指标等能力，分别对接 yfinance、akshare、easyquotation、Tushare 等，连接逻辑、字段映射、错误处理散落在多处（providers、historical_data_fetcher、field_mapper）。
- **扩展成本高**：每增加一个数据源，都要在多个业务服务里改「该调谁、怎么映射、怎么容错」，容易漏改、难测试。
- **调用方耦合**：上游（股票信息服务、历史数据服务）直接依赖「具体用哪个库、哪个 API」，一旦换数据源或做 A/B，影响面大。

### 1.2 目标

- **单一数据入口**：所有「从外部拿股票/ K 线数据」的请求，都经过一个统一服务，由它决定「调哪个数据源、怎么映射、怎么容错」。
- **可插拔数据源**：新增/下线数据源只改「一个适配实现 + 配置」，不动路由与业务逻辑。
- **可观测**：一次请求从入口到具体数据源调用，整条链可追踪、可排障。

一句话：**把「数据从哪来、怎么来」从业务服务里抽出来，收口到一个可插拔、可路由、可观测的 Proxy 层。**

---

## 二、设计思路一：职责边界先于技术选型

### 2.1 先回答「谁负责什么」

设计时先划清**边界**，再谈接口与实现：

| 职责 | 归属 | 理由 |
|------|------|------|
| 选择数据源、转发请求、容错重试 | 数据源服务 | 与「具体调哪个 API」强相关，和业务（持久化、指标计算）无关 |
| 字段映射、统一模型输出 | 数据源服务 | 不同数据源结构各异，必须在「出口」统一，调用方只认一种模型 |
| 股票/K 线持久化、缓存、调度 | 业务服务 | 属于业务与运维，数据源服务只做「实时取数」 |
| 指标计算 | 指标服务 | 与数据源服务解耦，通过统一模型消费即可 |

这样做的效果：

- **数据源服务**只做「输入请求 → 选源 → 取数 → 转成标准结果 → 输出」，不碰 DB、不碰调度。
- **业务服务**只依赖「标准 API + 标准模型」，不关心底层是 yfinance 还是 akshare。
- 未来若要换数据源、做多源融合或限流，改动都集中在数据源服务内部。

### 2.2 在 SPEC 中的体现

- **PRD**：用 EARS 明确「When 调用方请求 X，the system shall 做 Y，且不负责 Z」。
- **架构 overview**：用一张「API 层 → 应用服务 → Router → Provider → 外部数据源」的分层图固定职责，并注明「Router 只选源+转发，Provider 只取数+映射」。

**设计思路**：**职责边界优先**——先定「谁该做什么、不该做什么」，再设计接口和分层，避免层与层之间职责模糊、互相渗透。

---

## 三、设计思路二：用「抽象 + 注册表」实现插件化

### 3.1 为什么是「插件式」而不是「写死 if/else」？

若按「写死」方式，会变成：

```text
if (data_source == "akshare") return await akshare.fetch(...)
else if (data_source == "yfinance") return await yfinance.fetch(...)
else ...
```

问题：

- 每加一个数据源都要改这段逻辑，违反开闭原则。
- 容错、优先级、按市场筛选等策略和「具体是谁」搅在一起，难以单独演进。
- 测试时要 mock 一堆具体实现，而不是「一个 IRouter + 一个 MockProvider」。

所以目标变成：**路由逻辑不依赖任何具体数据源实现，只依赖「能提供某能力的抽象」+「一个可查询的注册表」。**

### 3.2 抽象什么、怎么扩展？

抽象的是**能力**，不是「某个库」：

- **IStockMetaProvider**：能提供「单只/批量元信息、列表」的，都实现这个接口；内部用 akshare 还是 yfinance 对 Router 透明。
- **IKlineProvider**：能提供「历史 K 线」的，实现这个接口；一个实现类可以同时实现两个接口（如 AkshareProvider 既提供元信息也提供 K 线）。
- **IProviderMetadata**：name、supported_markets、priority、features，用于「谁能接这个请求、按什么顺序试」。

这样：

- **扩展**：新数据源 = 新类实现上述接口 + 在配置里启用；Router/Registry 代码零修改。
- **路由**：按 market、data_source、feature 从 Registry 查「候选列表」，按 priority 排序后依次调用，失败就下一个，直到成功或耗尽。
- **测试**：可以只注册一个 MockProvider，验证「路由是否按优先级、是否容错」而不碰真实网络。

### 3.3 注册表扮演什么角色？

**IRegistry** 负责：

- **存**：`register(provider)`，按 name 存，按 market/feature 建索引（便于「给我所有支持 A股 + stock_info 的 Provider，按 priority 排」）。
- **查**：`getByName`（指定数据源时用）、`getByMarket(market, feature)`（未指定时用）、`getAll()`（能力查询接口用）。
- **生命周期**：启动时根据配置构造 Provider 并 register；可选支持热更新（unregister + register）。

Router 只依赖 IRegistry 和接口类型，不依赖「当前到底注册了哪几个具体类」。这样：

- **动态注册**：配置驱动，哪些数据源启用、优先级多少，都来自配置。
- **动态调度**：每次请求根据参数查 Registry，得到「当前」的候选列表，自然支持运行中变更（若实现热更新）。
- **动态扩展**：新写一个 Provider 实现类并加入配置即可，无需改 Router/Registry 实现。

### 3.4 在 SPEC 中的体现

- **architecture/interfaces.md**：定义 IProviderMetadata、IStockMetaProvider、IKlineProvider、IRegistry、IRouter、IFieldMapper，语言中立，实现时映射到 Python ABC 或 TypeScript interface。
- **architecture/registry.md**：约定注册时机、发现方式、与配置的配合。
- **architecture/design-patterns.md**：显式写出「策略模式（多数据源多策略）、注册表模式（可插拔集合）、适配器模式（外部 API → 统一模型）」。

**设计思路**：**抽象能力 + 注册表**——用接口描述「能做什么」，用注册表描述「当前谁在做」；路由与扩展都建立在这两层之上，实现插件化与开闭原则。

---

## 四、设计思路三：统一模型是「契约」而不是实现细节

### 4.1 为什么强调「统一模型」？

各数据源返回结构完全不同（yfinance 的 info 字典、akshare 的 DataFrame/中文列名、Tushare 的 ts_code 等）。若让调用方直接面对这些差异：

- 每个上游都要写一堆「如果是 akshare 就取这个字段，如果是 yfinance 就取那个字段」。
- 换数据源或做多源融合时，所有调用方都要改。

所以**数据源服务的出口必须只有一套类型**：例如 **Stock**（元信息）、**Kline**（单条 K 线）。所有 Provider 在内部做完「原始响应 → 统一模型」的映射，对外只暴露这一套。

### 4.2 用 OpenAPI 把模型写成契约

- 在 **model/schemas.yaml** 里用 OpenAPI 3.0 定义 Stock、Kline、ApiResponse、能力查询的 data 结构等。
- 约定：所有成功响应里的业务数据都符合这些 schema；未定义字段不出现，缺失字段用 null 或省略。

这样：

- **调用方**可以按 schema 生成类型、做校验、写文档。
- **实现方**有明确目标：Provider 的职责就是把「原始数据」映射成 schema 里的形状；测试可以「给一份原始响应，断言映射后的对象符合 schema」。
- **演进**：新增字段先改 schema 并注明兼容性，再在 Provider 里补映射；避免「实现里悄悄多了一个字段但文档没有」。

### 4.3 在 SPEC 中的体现

- **model/schemas.yaml**：完整定义 ApiResponse、Stock、Kline、StockBatchData、StockListData、KlineResponseData、ProviderInfo、CapabilityResponseData。
- **PRD**：多处写「the system shall 保证返回符合 [model/schemas.yaml]」，把「统一模型」变成可验收条款。

**设计思路**：**统一模型即契约**——用 OpenAPI 把「对外长什么样」写死；实现和测试都围绕这份契约，避免各说各话和隐式约定。

---

## 五、设计思路四：错误与可观测性也是架构的一部分

### 5.1 错误码与分层职责

- **错误码**（error/error-codes.md）：把「参数错误、未找到、限流、服务不可用」等语义固定成 400/404/429/503，并约定每种情况谁负责返回（API 层统一封装，Router 只返回 null 或抛业务异常，由上层转成 code）。
- **异常处理**（error/exception-handling.md）：区分「可重试 / 不可重试」、Router 层「当前 Provider 失败就试下一个」、Provider 层「不泄露凭证明文」等，避免各层随意抛、随意吞。

这样调用方和网关可以按 code 做重试、降级、告警；运维可以根据日志和 Trace 定位到「是哪个 Provider、哪一层」出的问题。

### 5.2 全链路追踪是「架构可观测性」

- **observability/opentelemetry.md**：约定从 API 入口 → Router → 每个 Provider 尝试，都落在同一个 Trace 里，用 Span 区分「请求入口」「路由选择」「某 Provider 调用」；属性里带 provider.name、market、ticker、attempt_count 等。
- 这样一次请求「试了哪几个数据源、谁成功谁失败、耗时在哪」一目了然；TraceId 可以写进响应头或日志，方便跨系统排查。

**设计思路**：**错误与可观测性不是事后补的**——在架构里就约定「错误怎么分层、怎么码化」「追踪打在哪几层、带哪些属性」，实现时按 SPEC 打点即可形成可运维的体系。

---

## 六、整体架构图（思路小结）

```text
                    ┌─────────────────────────────────────────────────────────┐
                    │  调用方（只依赖「标准 API + 标准模型」）                   │
                    └───────────────────────────┬─────────────────────────────┘
                                                │
  ┌─────────────────────────────────────────────▼─────────────────────────────┐
  │  API 层：参数校验、调用应用服务、统一响应格式、错误码映射、Trace 入口      │
  └───────────────────────────────┬───────────────────────────────────────────┘
                                  │
  ┌───────────────────────────────▼───────────────────────────────────────────┐
  │  应用服务层：编排 Router，不关心具体 Provider；返回统一模型                 │
  └───────────────────────────────┬───────────────────────────────────────────┘
                                  │
  ┌───────────────────────────────▼───────────────────────────────────────────┐
  │  路由层：只依赖 IRegistry + IStockMetaProvider/IKlineProvider            │
  │          按 market/data_source/feature 查候选 → 按 priority 试 → 容错     │
  └───────────────────────────────┬───────────────────────────────────────────┘
                                  │
  ┌───────────────────────────────▼───────────────────────────────────────────┐
  │  Provider 层：多个实现类（AkshareProvider、YFinanceProvider…）            │
  │              每个实现：调用外部 API + 映射为统一模型；注册到 Registry     │
  └───────────────────────────────┬───────────────────────────────────────────┘
                                  │
                    ┌─────────────▼─────────────┐
                    │  外部数据源（yfinance / akshare / …）  │
                    └──────────────────────────┘
```

- **职责清晰**：每层只做一件事，边界在 SPEC 里写死。
- **插件化**：Router 和 Registry 不依赖具体 Provider 类；扩展 = 新实现 + 配置注册。
- **契约统一**：对外只有一套 API 与一套模型（OpenAPI）；内部映射在 Provider 内完成。
- **可运维**：错误码统一、Trace 贯穿各层，便于排障与演进。

---

## 七、总结：技术架构设计思路的几条原则

通过数据源服务这个 Case Study，可以归纳出这样的设计思路：

1. **职责边界优先**：先确定「谁负责什么、不负责什么」，再设计接口与分层，避免层与层耦合、改一处动全身。
2. **用抽象 + 注册表做插件化**：用接口描述「能力」，用注册表描述「当前谁提供能力」；路由与扩展都建立在这之上，实现动态调度、动态扩展、动态注册。
3. **统一模型即契约**：用 OpenAPI 把对外类型写死，所有出口都符合这份契约；实现和测试都围绕契约，便于演进与多端一致。
4. **错误与可观测性入架构**：错误码分层、异常可重试/不可重试、Trace/Span 打点位置与属性，都在 SPEC 里约定，而不是实现时随意发挥。
5. **SPEC 固化决策**：上述内容都落在 prd、model、architecture、error、observability 等目录中，开发前可评审、开发中可执行、联调与验收有据可查。

这样，技术架构不仅「能跑」，而且「易扩展、易排障、易协作」；Case Study 本身也成了一份可复用的架构设计说明。
