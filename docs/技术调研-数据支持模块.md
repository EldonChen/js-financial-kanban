# 技术调研 - 数据支持模块

> **调研时间**：2025-01-12  
> **调研目的**：为数据支持模块的技术选型和架构设计提供依据

## 1. MongoDB TimeSeries Collection 深度调研

### 1.1 TimeSeries Collection 特性

#### 核心特性
- **自动压缩**：MongoDB 自动压缩时间序列数据，节省存储空间（通常可节省 50-90%）
- **查询优化**：针对时间范围查询进行了优化，性能比普通 Collection 提升 2-10 倍
- **Metafield 支持**：支持设置 metafield，用于存储不经常变化的元数据
- **自动归档**：MongoDB 5.0+ 支持自动归档到冷存储（需要配置）

#### Metafield 设计
```python
# TimeSeries Collection 创建示例
db.create_collection(
    "kline_data",
    timeseries={
        "timeField": "timestamp",      # 时间字段
        "metaField": "metadata",       # 元数据字段（不经常变化的数据）
        "granularity": "hours"         # 粒度：seconds, minutes, hours
    }
)

# 文档结构
{
    "_id": ObjectId,
    "timestamp": ISODate("2025-01-12T09:30:00Z"),  # 时间字段
    "metadata": {                                    # 元数据字段（不经常变化）
        "ticker": "AAPL",
        "market": "NASDAQ",
        "period": "1d"
    },
    "open": 150.25,     # 测量字段（经常变化）
    "high": 152.30,
    "low": 149.80,
    "close": 151.50,
    "volume": 50000000
}
```

**Metafield 的优势**：
- ✅ **存储优化**：metafield 数据只存储一次，多个时间点共享，节省存储空间
- ✅ **查询优化**：MongoDB 可以基于 metafield 进行分区和索引优化
- ✅ **数据组织**：逻辑上相关的时间序列数据组织在一起

**Metafield 的限制**：
- ⚠️ **不可频繁更新**：metafield 不应该频繁变化，否则会影响性能
- ⚠️ **查询限制**：对 metafield 的查询需要配合时间字段使用

### 1.2 股票信息作为 Metafield 的设计

**设计思路**：
- 股票基本信息（ticker, market, period）作为 metafield
- K线数据（open, high, low, close, volume）作为测量字段
- 股票详细信息（name, sector, industry 等）存储在独立的 `stocks` 集合中，通过 ticker 引用

**文档结构设计**：
```python
# kline_data 集合（TimeSeries Collection）
{
    "_id": ObjectId,
    "timestamp": ISODate("2025-01-12T09:30:00Z"),
    "metadata": {
        "ticker": "AAPL",        # 股票代码（作为 metafield）
        "market": "NASDAQ",       # 市场（作为 metafield）
        "period": "1d"            # 时间周期（作为 metafield）
    },
    "open": 150.25,
    "high": 152.30,
    "low": 149.80,
    "close": 151.50,
    "volume": 50000000,
    "amount": 7500000000,
    "adj_close": 151.50,
    "data_source": "yfinance"
}

# stocks 集合（普通 Collection，存储股票详细信息）
{
    "_id": ObjectId,
    "ticker": "AAPL",
    "name": "Apple Inc.",
    "market": "NASDAQ",
    "market_type": "美股",
    "sector": "Technology",
    "industry": "Consumer Electronics",
    "currency": "USD",
    "exchange": "NMS",
    "country": "United States",
    "market_cap": 2500000000000,
    "pe_ratio": 28.5,
    "pb_ratio": 45.2,
    "dividend_yield": 0.005,
    "listing_date": ISODate("1980-12-12"),
    "data_source": "yfinance",
    "created_at": ISODate,
    "updated_at": ISODate
}
```

**查询方式**：
```python
# 查询特定股票的历史K线数据
db.kline_data.find({
    "metadata.ticker": "AAPL",
    "metadata.period": "1d",
    "timestamp": {
        "$gte": ISODate("2025-01-01"),
        "$lte": ISODate("2025-01-12")
    }
})

# 如果需要股票详细信息，通过 ticker 关联查询
kline_data = db.kline_data.find({"metadata.ticker": "AAPL"})
stock_info = db.stocks.find_one({"ticker": "AAPL"})
```

### 1.3 冷热数据分离方案

#### MongoDB 自动归档（MongoDB 5.0+）
- **自动归档**：MongoDB 支持自动将旧数据归档到冷存储（需要配置归档策略）
- **查询透明**：归档后的数据仍然可以查询，MongoDB 自动从冷存储加载
- **配置示例**：
```javascript
// 创建归档策略（90天后的数据自动归档）
db.createCollection("kline_data", {
    timeseries: {
        timeField: "timestamp",
        metaField: "metadata",
        granularity: "hours"
    },
    expireAfterSeconds: 7776000  // 90天 = 7776000秒
})
```

#### 手动冷热数据分离
**方案1：按时间分区（推荐）**
- **热数据集合**：`kline_data_recent`（最近 1 年的数据）
- **冷数据集合**：`kline_data_archive_2024`、`kline_data_archive_2023` 等（历史数据）
- **查询逻辑**：先查询热数据，如果时间范围超出，再查询冷数据

**方案2：使用 MongoDB Atlas 自动归档**
- **Atlas Online Archive**：MongoDB Atlas 支持自动归档到 S3
- **查询透明**：归档后的数据仍然可以查询
- **成本优化**：冷数据存储在 S3，成本更低

**方案3：应用层分离**
- **热数据**：存储在 MongoDB，使用 Redis 缓存
- **冷数据**：存储在对象存储（S3/OSS），需要时再加载

**推荐方案**：
- **当前阶段**：使用单一 TimeSeries Collection，依赖 MongoDB 的自动压缩
- **数据量 > 1 亿条**：考虑按时间分区（方案1）
- **使用 MongoDB Atlas**：使用 Atlas Online Archive（方案2）

### 1.4 文档引用 vs 嵌入

**股票信息存储策略**：

**方案1：文档引用（推荐）**
```python
# kline_data 集合（TimeSeries Collection）
{
    "metadata": {
        "ticker": "AAPL",  # 只存储 ticker，通过引用获取详细信息
        "market": "NASDAQ",
        "period": "1d"
    },
    "timestamp": ISODate("2025-01-12T09:30:00Z"),
    "open": 150.25,
    # ...
}

# stocks 集合（普通 Collection）
{
    "ticker": "AAPL",
    "name": "Apple Inc.",
    "sector": "Technology",
    # ... 其他详细信息
}
```

**优势**：
- ✅ **数据一致性**：股票信息更新时，只需要更新 `stocks` 集合
- ✅ **存储优化**：避免在时间序列数据中重复存储股票信息
- ✅ **扩展性**：股票信息可以随时添加新字段，不影响时间序列数据
- ✅ **查询灵活性**：可以独立查询股票信息，也可以关联查询

**劣势**：
- ⚠️ **查询复杂度**：需要两次查询（先查 kline_data，再查 stocks）
- ⚠️ **性能影响**：关联查询可能比嵌入查询慢（但可以通过应用层缓存优化）

**方案2：文档嵌入（不推荐）**
```python
# kline_data 集合
{
    "metadata": {
        "ticker": "AAPL",
        "market": "NASDAQ",
        "period": "1d",
        "name": "Apple Inc.",      # 嵌入股票信息
        "sector": "Technology",    # 嵌入股票信息
        # ...
    },
    "timestamp": ISODate("2025-01-12T09:30:00Z"),
    "open": 150.25,
    # ...
}
```

**劣势**：
- ❌ **数据冗余**：每个时间点都存储股票信息，浪费存储空间
- ❌ **更新困难**：股票信息更新时，需要更新所有相关的时间序列数据
- ❌ **扩展性差**：添加新字段需要更新所有历史数据

**结论**：**推荐使用文档引用**，股票信息存储在独立的 `stocks` 集合中，时间序列数据只存储 ticker 引用。

## 2. Apache Flink 在技术指标计算中的应用调研

### 2.1 Flink 简介

**Apache Flink** 是一个分布式流处理和批处理框架，具有以下特点：
- **低延迟**：流处理延迟可低至毫秒级
- **高吞吐**：支持大规模数据处理
- **状态管理**：支持有状态计算，适合技术指标计算
- **容错性**：支持故障恢复，保证数据一致性

### 2.2 Flink 在技术指标计算中的应用场景

#### 适用场景
1. **实时技术指标计算**：
   - 实时计算 MA、RSI、MACD 等指标
   - 支持流式数据输入（实时行情数据）
   - 低延迟输出（毫秒级）

2. **批量技术指标计算**：
   - 批量计算历史数据的指标
   - 支持大规模数据并行处理
   - 高性能计算（比单机计算快 10-100 倍）

3. **复杂指标计算**：
   - 支持窗口函数（滑动窗口、滚动窗口）
   - 支持状态管理（如 MACD 需要维护历史状态）
   - 支持自定义函数（UDF）

#### 不适用场景
1. **小规模数据**：
   - 数据量 < 100 万条，Flink 的启动开销可能大于计算收益
   - 单机计算已经足够快

2. **简单指标计算**：
   - 简单的移动平均线计算，使用 pandas 已经足够
   - 不需要分布式计算

3. **实时性要求不高**：
   - 如果只需要每日计算一次，使用定时任务 + pandas 更简单

### 2.3 Flink vs 传统计算方法对比

| 特性 | Flink | TA-Lib/pandas | 说明 |
|------|-------|---------------|------|
| **性能** | 极高（分布式） | 高（单机） | Flink 支持分布式计算，性能更高 |
| **延迟** | 毫秒级 | 秒级 | Flink 支持流式处理，延迟更低 |
| **复杂度** | 高 | 低 | Flink 需要集群部署，复杂度高 |
| **成本** | 高 | 低 | Flink 需要额外的计算资源 |
| **适用场景** | 大规模实时计算 | 中小规模批量计算 | 根据数据规模和实时性要求选择 |

### 2.4 Flink 集成方案

#### 方案1：Flink 独立服务（推荐用于大规模场景）
```
┌─────────────┐
│  FastAPI    │
│   Service   │
└──────┬──────┘
       │
       │ 提交计算任务
       ▼
┌─────────────┐
│   Flink     │
│   Cluster   │
└──────┬──────┘
       │
       │ 读取数据
       ▼
┌─────────────┐
│  MongoDB    │
│  (K线数据)  │
└─────────────┘
```

**优势**：
- ✅ **高性能**：分布式计算，性能极高
- ✅ **可扩展**：可以水平扩展，支持更大规模数据
- ✅ **解耦**：Flink 服务独立，不影响主服务

**劣势**：
- ⚠️ **复杂度高**：需要部署 Flink 集群
- ⚠️ **成本高**：需要额外的计算资源
- ⚠️ **运维复杂**：需要监控和管理 Flink 集群

#### 方案2：Flink 嵌入服务（不推荐）
- 在 FastAPI 服务中嵌入 Flink，复杂度高，不推荐

#### 方案3：混合方案（推荐用于当前阶段）
```
┌─────────────────────────────────────┐
│         FastAPI Service              │
│  ┌──────────────┐  ┌──────────────┐ │
│  │  小规模计算   │  │  大规模计算   │ │
│  │  (TA-Lib)    │  │  (Flink API)  │ │
│  └──────────────┘  └──────────────┘ │
└─────────────────────────────────────┘
```

**策略**：
- **小规模计算**（单只股票、少量指标）：使用 TA-Lib/pandas，在 FastAPI 服务中直接计算
- **大规模计算**（批量股票、大量指标）：调用 Flink 服务，异步计算

### 2.5 Flink 实施建议

#### 当前阶段（不推荐使用 Flink）
**理由**：
- 数据规模较小（< 1000 万条）
- 实时性要求不高（每日计算一次即可）
- 单机计算已经足够快（TA-Lib 性能已经很高）
- Flink 的部署和运维成本较高

**建议**：
- 使用 TA-Lib/pandas 进行技术指标计算
- 如果后续数据规模扩大（> 1 亿条）或需要实时计算，再考虑引入 Flink

#### 未来阶段（考虑引入 Flink）
**触发条件**：
- 数据规模 > 1 亿条
- 需要实时计算技术指标（延迟 < 1 秒）
- 需要批量计算 1000+ 只股票的指标
- 单机计算性能成为瓶颈

**实施步骤**：
1. 部署 Flink 集群（3-5 个节点）
2. 开发 Flink Job，实现技术指标计算逻辑
3. 在 FastAPI 服务中集成 Flink API，支持异步提交计算任务
4. 实现混合方案：小规模计算用 TA-Lib，大规模计算用 Flink

## 3. 服务拆分设计调研

### 3.1 当前服务结构分析

**现有服务结构**：
```
services/py-stock-info-service/
├── app/
│   ├── services/
│   │   ├── stock_service.py          # 股票信息服务（600+ 行）
│   │   ├── yfinance_service.py       # yfinance 数据获取服务
│   │   └── providers/                # 数据源提供者
│   ├── routers/
│   │   └── stocks.py                 # 股票路由
│   └── models/
│       └── stock.py                   # 股票模型
```

**问题**：
- `stock_service.py` 文件过大（600+ 行），包含太多职责
- 数据获取、数据存储、数据查询逻辑混在一起
- 难以测试和维护

### 3.2 服务拆分原则

#### 单一职责原则（SRP）
- 每个服务类只负责一个功能领域
- 避免一个类包含太多方法

#### 依赖倒置原则（DIP）
- 服务之间通过接口依赖，而不是直接依赖实现
- 便于测试和替换实现

#### 开闭原则（OCP）
- 对扩展开放，对修改关闭
- 通过组合而非继承实现功能扩展

### 3.3 服务拆分方案

#### 方案1：按功能领域拆分（推荐）

```
services/py-stock-info-service/
├── app/
│   ├── services/
│   │   ├── stock/                      # 股票服务模块
│   │   │   ├── __init__.py
│   │   │   ├── stock_service.py       # 股票基本信息服务（核心逻辑）
│   │   │   ├── stock_query_service.py  # 股票查询服务（查询逻辑）
│   │   │   └── stock_update_service.py # 股票更新服务（更新逻辑）
│   │   │
│   │   ├── historical_data/            # 历史数据服务模块
│   │   │   ├── __init__.py
│   │   │   ├── historical_data_service.py      # 历史数据核心服务
│   │   │   ├── historical_data_fetcher.py      # 数据获取服务
│   │   │   ├── historical_data_storage.py      # 数据存储服务
│   │   │   └── historical_data_query.py        # 数据查询服务
│   │   │
│   │   ├── indicators/                 # 技术指标服务模块
│   │   │   ├── __init__.py
│   │   │   ├── indicator_service.py            # 技术指标核心服务
│   │   │   ├── indicator_calculator.py         # 指标计算服务
│   │   │   ├── indicator_storage.py             # 指标存储服务
│   │   │   └── indicator_query.py               # 指标查询服务
│   │   │
│   │   ├── data_quality/                # 数据质量服务模块
│   │   │   ├── __init__.py
│   │   │   ├── data_quality_service.py          # 数据质量核心服务
│   │   │   ├── completeness_checker.py          # 完整性检查
│   │   │   ├── accuracy_checker.py              # 准确性检查
│   │   │   ├── consistency_checker.py           # 一致性检查
│   │   │   └── data_fixer.py                    # 数据修复
│   │   │
│   │   ├── data_sync/                  # 数据同步服务模块
│   │   │   ├── __init__.py
│   │   │   ├── data_sync_service.py             # 数据同步核心服务
│   │   │   ├── sync_scheduler.py                # 同步调度器
│   │   │   └── sync_executor.py                  # 同步执行器
│   │   │
│   │   └── providers/                  # 数据源提供者（保持不变）
│   │
│   ├── routers/
│   │   ├── stocks.py                   # 股票路由（保持不变）
│   │   ├── historical_data.py          # 历史数据路由
│   │   ├── indicators.py               # 技术指标路由
│   │   ├── data_quality.py              # 数据质量路由
│   │   └── data_sync.py                 # 数据同步路由
│   │
│   └── models/
│       ├── stock.py                     # 股票模型（保持不变）
│       ├── kline_data.py                # K线数据模型
│       └── indicator_data.py            # 指标数据模型
```

**优势**：
- ✅ **职责清晰**：每个服务类只负责一个功能领域
- ✅ **易于测试**：可以独立测试每个服务
- ✅ **易于维护**：代码组织清晰，易于查找和修改
- ✅ **易于扩展**：可以独立扩展每个功能模块

**劣势**：
- ⚠️ **文件数量增加**：需要创建更多文件
- ⚠️ **依赖管理**：需要管理服务之间的依赖关系

#### 方案2：按数据流拆分（不推荐）
- 按数据流（获取 → 存储 → 查询）拆分，会导致服务之间耦合度高

### 3.4 服务依赖关系设计

```
┌─────────────────────┐
│  HistoricalData     │
│     Service         │
└──────────┬──────────┘
           │ 依赖
           ▼
┌─────────────────────┐
│  StockService       │  (获取股票列表)
└─────────────────────┘

┌─────────────────────┐
│  IndicatorService  │
└──────────┬──────────┘
           │ 依赖
           ▼
┌─────────────────────┐
│  HistoricalData     │  (获取K线数据)
│     Service         │
└─────────────────────┘

┌─────────────────────┐
│  DataQualityService │
└──────────┬──────────┘
           │ 依赖
           ▼
┌─────────────────────┐
│  HistoricalData     │  (检查数据质量)
│     Service         │
└─────────────────────┘

┌─────────────────────┐
│  DataSyncService    │
└──────────┬──────────┘
           │ 依赖
           ▼
┌─────────────────────┐
│  HistoricalData     │  (同步数据)
│     Service         │
└─────────────────────┘
```

## 4. 向后兼容性设计

### 4.1 现有服务不受影响

**设计原则**：
- 新增功能不影响现有功能
- 新增集合不影响现有集合
- 新增路由不影响现有路由

### 4.2 兼容性保证措施

1. **独立集合**：
   - 历史K线数据使用新集合 `kline_data`，不影响现有 `stocks` 集合
   - 技术指标数据使用新集合 `indicator_data`

2. **独立路由**：
   - 历史数据路由：`/api/v1/historical-data/*`
   - 技术指标路由：`/api/v1/indicators/*`
   - 不影响现有股票路由：`/api/v1/stocks/*`

3. **独立服务**：
   - 新增服务类不影响现有 `StockService`
   - 可以独立部署和测试

4. **渐进式迁移**：
   - 可以先实现新功能，不影响现有功能
   - 后续可以逐步迁移现有功能到新架构

## 5. 总结与建议

### 5.1 数据库设计建议

1. **使用 TimeSeries Collection**：
   - ✅ 使用 MongoDB TimeSeries Collection 存储历史K线数据
   - ✅ 使用 metafield 存储不经常变化的数据（ticker, market, period）
   - ✅ 股票详细信息存储在独立的 `stocks` 集合中，通过 ticker 引用

2. **冷热数据分离**：
   - ✅ 当前阶段：使用单一 TimeSeries Collection，依赖 MongoDB 自动压缩
   - ✅ 数据量 > 1 亿条：考虑按时间分区或使用 Atlas Online Archive

3. **文档引用**：
   - ✅ 推荐使用文档引用，股票信息存储在独立的 `stocks` 集合中
   - ✅ 时间序列数据只存储 ticker 引用，避免数据冗余

### 5.2 计算架构建议

1. **当前阶段**：
   - ✅ 使用 TA-Lib/pandas 进行技术指标计算
   - ✅ 不引入 Flink（数据规模较小，单机计算足够）

2. **未来阶段**：
   - ✅ 如果数据规模 > 1 亿条或需要实时计算，再考虑引入 Flink
   - ✅ 采用混合方案：小规模计算用 TA-Lib，大规模计算用 Flink

### 5.3 服务拆分建议

1. **按功能领域拆分**：
   - ✅ 将服务按功能领域拆分为独立模块（stock, historical_data, indicators, data_quality, data_sync）
   - ✅ 每个模块内部按职责进一步拆分（核心服务、获取服务、存储服务、查询服务）

2. **保持向后兼容**：
   - ✅ 新增功能不影响现有功能
   - ✅ 使用独立集合、独立路由、独立服务

### 5.4 实施优先级

1. **Phase 1**：数据库设计和模型实现
   - MongoDB TimeSeries Collection 设计
   - 数据模型实现
   - 索引创建

2. **Phase 2**：核心服务实现
   - 历史数据服务（按功能拆分）
   - 技术指标服务（按功能拆分）

3. **Phase 3**：API 接口实现
   - 历史数据接口
   - 技术指标接口

4. **Phase 4**：数据质量和服务完善
   - 数据质量检查服务
   - 数据同步服务
